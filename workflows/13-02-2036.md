# Cose da fare

Allora sono tornato indietro un pò sul codice, che l'api per processare il file da trasformare in chuncks non mi piaceva.
Quindi torniamo sulla idea iniziale dello scheduler.
Ho rimesso il job ogni 5 minuti (dimmi se secondo te va bene), lo riabilito nel file main.py.

Quindi ricontrolliamo insieme la parte Fe.

MI aspetto:

- login
- form per caricare il file
- lista dei documenti ( se sono admin in questo caso devo vedere chi ha caricato cosa)
- nelle azioni ci sono :
  - vedi lista chuncks se è stato processato
  - vedi errori se il file processato si è rotto (attraverso una modale)

## Da fare:

1. quando lo scheduler prende in carico un documento lo mette in stato pending e quindi dobbiamo aggiungere qualcosa lato FE nella lista che attesti ciò.
   - [FATTO] Creata funzione `update_pending` nel model `Documents`.
   - [FATTO] Implementata logica in `DocumentsJobs` per settare `pending` prima del processing.
   - [FATTO] Aggiunta traduzione e stile (spinner) nel FE per lo stato `pending`.

2. quando lo scheduler ha finito di processare il documento lo mette in stato done e quindi dobbiamo aggiungere qualcosa lato FE nella lista che attesti ciò.
   - [FATTO] Lo stato passa a `processed` al termine del job.
   - [FATTO] FE aggiornato per mostrare il pulsante "Vedi Chunks" quando lo stato è `processed`.

3. dobbiamo dare un occhio allo scheduler (prima di compiere azioni ragioniamo insieme)
   - [FATTO] Riabilitato lo scheduler in `main.py`.
   - [FATTO] Fixato il percorso dei file in `DocumentsJobs` (ora punta correttamente a `import-data/`).
   - [FATTO] Aggiornate tutte le chiamate API nel FE per riflettere le nuove rotte (`/api/documents` e `/api/jobs`).
   - [FATTO] Rimossa la possibilità di avviare l'elaborazione manualmente dal FE (ora gestita solo dallo scheduler).
   - [FATTO] Corretto bug parametri in `jobs_controller.py`.
   - [FATTO] Fixato errore "create_token is undefined" in `user_controller.py` aggiungendo l'import corretto.
   - [FATTO] Fixato bug `ModelGeneral.count_search` che impediva all'admin di vedere la lista documenti (gestione parametri `None`).
   - [FATTO] Migliorato logging errori nel controller utenti per debug facilitato (uso di `str(e)`).
   - [FATTO] Implementata logica di **Retry (3 tentativi)** in `DocumentsJobs.py`: se un file fallisce, lo scheduler riprova fino a 3 volte prima di segnarlo definitivamente come `error`.
   - [FATTO] Implementato **Logging su CSV** (`scheduler_log.csv`): mappatura di ogni tentativo con TIMESTAMP, FILE, STATO, NOTE ed ECCEZIONE.
   - [FATTO] Configurato lo scheduler per processare sia i file `uploaded` che quelli in stato `error`.
   - [FATTO] Risolto bug di ricorsione infinita nel model `JobsFailed`.
   - [FINE] Sistema di tracciamento e robustezza completato. Pronto per il test.

## Note Finali Sessione 13/02/2026:

- Lo scheduler è operativo e correttamente configurato.
- **Test Esito**: Il file `.txt` è stato processato con successo (chunk creati). Gli altri file (Excel) sono andati in errore nonostante i retry.
- **Prossimi Passi**: Alla ripresa, sarà necessario testare lato Python le classi di chunking per capire come vengono divisi i file e risolvere i problemi sui formati non testuali.

## NOTA

Se il file per x motivi, sia stato lavorato in parte dallo scheduler, ed questo è terminato con errore (stato sul file nella tabella _error_), al giro successivo prima di procedere, è necessario eliminare gli eventuali chunck già salvati sul db (tabella _chunks_)
